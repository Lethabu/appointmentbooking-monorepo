name: ğŸ” Code Quality Gates

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18'
  PNPM_VERSION: '8'

jobs:
  quality-gates:
    name: ğŸ›¡ï¸ Quality Gates
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: ğŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ’¾ Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.pnpm-store
            **/node_modules
          key: ${{ runner.os }}-pnpm-${{ hashFiles('**/pnpm-lock.yaml') }}

      - name: ğŸ“¥ Install dependencies
        run: pnpm install --frozen-lockfile

      # ğŸ” LINTING & CODE ANALYSIS
      - name: ğŸ” ESLint Analysis
        run: pnpm run lint
        continue-on-error: false

      - name: ğŸ¨ Prettier Check
        run: pnpm run format:check
        continue-on-error: false

      - name: ğŸ“ TypeScript Check
        run: pnpm run type-check
        continue-on-error: false

      # ğŸ§ª TESTING
      - name: ğŸ§ª Unit Tests
        run: pnpm run test:unit
        continue-on-error: false

      - name: ğŸ§ª Integration Tests
        run: pnpm run test:integration
        continue-on-error: false

      - name: ğŸ§ª E2E Tests
        run: pnpm run test:e2e
        continue-on-error: false

      # ğŸ“Š QUALITY METRICS
      - name: ğŸ“Š Generate Quality Report
        run: pnpm run quality:report

      - name: ğŸ“ˆ Upload Quality Report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: quality-report
          path: |
            reports/quality-metrics.json
            reports/quality-report.html
            reports/eslint-report.json

      # ğŸ”’ SECURITY SCANS
      - name: ğŸ”’ Security Audit
        run: pnpm audit --audit-level moderate
        continue-on-error: false

      - name: ğŸ›¡ï¸ Dependency Security Scan
        uses: actions/github-script@v6
        with:
          script: |
            const { execSync } = require('child_process');
            try {
              const output = execSync('pnpm audit --json', { encoding: 'utf8' });
              const auditResult = JSON.parse(output);
              
              if (auditResult.vulnerabilities) {
                const vulnerabilities = Object.values(auditResult.vulnerabilities);
                if (vulnerabilities.length > 0) {
                  core.setFailed(`Found ${vulnerabilities.length} security vulnerabilities`);
                }
              }
            } catch (error) {
              console.log('No vulnerabilities found or audit failed');
            }

      # ğŸ—ï¸ BUILD VERIFICATION
      - name: ğŸ—ï¸ Build Applications
        run: |
          pnpm run build:sequential
        continue-on-error: false

      - name: ğŸ“¦ Upload Build Artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: build-artifacts
          path: |
            apps/*/dist/
            apps/*/.next/
            packages/*/dist/

      # ğŸ“‹ CODE REVIEW REQUIREMENTS
      - name: ğŸ‘¥ Check Review Requirements
        uses: actions/github-script@v6
        with:
          script: |
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number
            });

            const requiredReviews = 2; // Configure based on team requirements
            const approvals = pr.requested_reviewers?.length || 0;
            
            if (approvals < requiredReviews) {
              core.warning(`This PR requires ${requiredReviews} reviews, but only has ${approvals} assigned`);
            }

      # ğŸ¯ QUALITY GATES THRESHOLDS
      - name: ğŸ¯ Quality Gates Verification
        run: |
          echo "ğŸ” Running quality gates verification..."
          
          # Check if quality metrics meet thresholds
          if [ -f "reports/quality-metrics.json" ]; then
            QUALITY_SCORE=$(jq -r '.summary.overallQuality' reports/quality-metrics.json)
            VIOLATIONS=$(jq -r '.summary.totalViolations' reports/quality-metrics.json)
            
            echo "Quality Score: $QUALITY_SCORE"
            echo "Total Violations: $VIOLATIONS"
            
            # Quality thresholds (configure as needed)
            MIN_QUALITY_SCORE=70
            MAX_VIOLATIONS=20
            
            if (( $(echo "$QUALITY_SCORE < $MIN_QUALITY_SCORE" | bc -l) )); then
              echo "âŒ Quality score $QUALITY_SCORE is below minimum threshold $MIN_QUALITY_SCORE"
              exit 1
            fi
            
            if [ "$VIOLATIONS" -gt "$MAX_VIOLATIONS" ]; then
              echo "âŒ Too many violations ($VIOLATIONS) exceed maximum threshold ($MAX_VIOLATIONS)"
              exit 1
            fi
            
            echo "âœ… Quality gates passed"
          else
            echo "âš ï¸ Quality metrics report not found, skipping threshold checks"
          fi

      # ğŸ“± PERFORMANCE MONITORING
      - name: âš¡ Performance Budget Check
        run: |
          echo "ğŸ” Checking performance budgets..."
          # Add performance budget checks here
          # Example: Bundle size, Core Web Vitals, etc.

      # ğŸ“š DOCUMENTATION
      - name: ğŸ“š Documentation Check
        run: |
          echo "ğŸ“š Checking documentation requirements..."
          # Ensure README, API docs, etc. are updated
          if [ -f "README.md" ]; then
            echo "âœ… README.md found"
          else
            echo "âŒ README.md missing"
            exit 1
          fi

  # ğŸš€ DEPLOYMENT GATE
  deploy-gate:
    name: ğŸš€ Deployment Gate
    runs-on: ubuntu-latest
    needs: [quality-gates]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: âœ… Quality Gates Passed
        run: |
          echo "ğŸ‰ All quality gates passed! Ready for deployment."
          echo "ğŸ“Š Review the quality report: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

  # ğŸ“Š QUALITY DASHBOARD
  quality-dashboard:
    name: ğŸ“Š Update Quality Dashboard
    runs-on: ubuntu-latest
    needs: [quality-gates]
    if: always()
    
    steps:
      - name: ğŸ“Š Download Quality Reports
        uses: actions/download-artifact@v3
        with:
          name: quality-report
          path: reports/

      - name: ğŸ“ˆ Update Quality Dashboard
        run: |
          echo "ğŸ“Š Updating quality dashboard..."
          # This could push metrics to a monitoring system
          # or update a dashboard with current quality status

      - name: ğŸ“¢ Notify Quality Status
        uses: actions/github-script@v6
        with:
          script: |
            const qualityReport = require('./reports/quality-metrics.json');
            const qualityScore = qualityReport.summary.overallQuality;
            
            let status = 'ğŸŸ¢';
            if (qualityScore < 70) status = 'ğŸ”´';
            else if (qualityScore < 85) status = 'ğŸŸ¡';
            
            const message = `${status} Code Quality Score: ${qualityScore}/100`;
            
            // You could post this to Slack, Teams, or other notification systems
            console.log(message);