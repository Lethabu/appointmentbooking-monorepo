# Local AI Orchestrator Environment Configuration
# Copy to .env and configure for your environment

# Service Configuration
ENVIRONMENT=production
PORT=8004
LOG_LEVEL=info

# CORS Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:8080,https://yourdomain.com

# Google AI API Configuration
GOOGLE_API_KEY=your_google_api_key_here

# Ollama Configuration
OLLAMA_HOST=ollama
OLLAMA_PORT=11434
OLLAMA_TIMEOUT=300

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000

# Monitoring and Observability
SENTRY_DSN=your_sentry_dsn_here
PROMETHEUS_PORT=9090

# Security
SECRET_KEY=your_secret_key_here
ALLOWED_HOSTS=localhost,127.0.0.1,yourdomain.com

# Resource Limits
MAX_MEMORY_USAGE=4GB
MAX_CPU_USAGE=2

# Model Configuration
DEFAULT_MODEL=llama2
FALLBACK_MODEL=phi3
HIGH_QUALITY_MODEL=gemini-2-flash

# Health Check Configuration
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10

# Timeout Configuration
REQUEST_TIMEOUT=300
STREAM_TIMEOUT=60

# Retry Configuration
MAX_RETRIES=3
RETRY_BACKOFF=1.5

# Performance Tuning
MAX_CONCURRENT_REQUESTS=10
MODEL_WARMUP_TIMEOUT=30

# Database (if needed for caching)
REDIS_URL=redis://redis:6379/0

# Logging Configuration
LOG_FORMAT=json
LOG_RETENTION_DAYS=30

# Feature Flags
ENABLE_AUTO_MODEL_SELECTION=true
ENABLE_STREAMING=true
ENABLE_WEBSOCKET=true
ENABLE_CACHING=true

# Development Options
ENABLE_DEBUG=false
ENABLE_PROFILING=false
ENABLE_CORS_DEBUG=false